{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robinjmf/Audio_Analysis/blob/main/Copy_of_GTZAN_Genre_Classification_Deep_Learning_Val_92_4_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'gtzan-dataset-music-genre-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F568973%2F1032238%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240820%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240820T064039Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2895a992d3cf77a2219e2129aea7d76c100ae9653b94265ace120c81375b72952c976cd64f26c94500f2d01ce53df7849bdcd975f54671c76b9d63f74e8bdba64520b1eb8373f922beaec0ee7b399bb7a7b044b6c65f694882ef2bbd7c6a98f52344fab0b9022ea66308bef17edb02826cce4c2df49eb46c951f92856ebb538dfe8d63403bad87b309cba6d33a9976e56aaa2e9d4e5cd026547c5c636eb175a8a381fc34e828e0517b51bcbe49748b9f8de980a65ad7ef6a4c49fc2da41fe315ed089d28e62bd52b58f99b77e06664369f6e498caf48bb7413b43eeb79a467555f384ac67254df03f5d423ae6f33281f26be28fda631ebb002d88ee373cc88d9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "USDv6deCh3xE"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "I0sgvyYch3xJ"
      },
      "cell_type": "markdown",
      "source": [
        "# GTZAN - Deep Learning\n",
        "\n",
        "`Music Genre Classification Problem`. Experts have been trying for a long time to understand sound & what differentiates one from another. How to visualize sound. What makes one tone different from another.\n",
        "\n",
        "We are going to analyze the features extracted from the GTZAN dataset and build different type of ensemble models to see how better we can differentiate one genre from another.\n",
        "\n",
        "Our Datasets contains 10 genres:-\n",
        "- Blues\n",
        "- Classical\n",
        "- Country\n",
        "- Disco\n",
        "- Hiphop\n",
        "- Jazz\n",
        "- Metal\n",
        "- Pop\n",
        "- Reggae\n",
        "- Rock\n"
      ]
    },
    {
      "metadata": {
        "id": "0NqzXRRdh3xL"
      },
      "cell_type": "markdown",
      "source": [
        "# Reading & Understanding Data\n",
        "## Importing Libraries"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sNXEGNiMh3xL"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sklearn.metrics as skm\n",
        "import sklearn.model_selection as skms\n",
        "import sklearn.preprocessing as skp\n",
        "import random\n",
        "import librosa, IPython\n",
        "import librosa.display as lplt\n",
        "seed = 12\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lv9KHSTbh3xM"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZxoBb-FVh3xM"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/gtzan-dataset-music-genre-classification/Data/features_3_sec.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuutvkiLh3xN"
      },
      "cell_type": "markdown",
      "source": [
        "### About the dataset"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "id": "8HoHDGhOh3xN"
      },
      "cell_type": "code",
      "source": [
        "print(\"Dataset has\",df.shape)\n",
        "print(\"Count of Positive and Negative samples\")\n",
        "df.label.value_counts().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JOXShnSdh3xN"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pxAVR6U8h3xO"
      },
      "cell_type": "code",
      "source": [
        "audio_fp = '/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/blues/blues.00000.wav'\n",
        "audio_data, sr = librosa.load(audio_fp)\n",
        "audio_data, _ = librosa.effects.trim(audio_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ikVVt7rhh3xO"
      },
      "cell_type": "code",
      "source": [
        "# play sample file\n",
        "IPython.display.Audio(audio_data, rate=sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RjSrMNtNh3xO"
      },
      "cell_type": "code",
      "source": [
        "# plot sample file\n",
        "plt.figure(figsize=(15,5))\n",
        "lplt.waveplot(audio_data)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_NhTMXXRh3xO"
      },
      "cell_type": "code",
      "source": [
        "# Default FFT window size\n",
        "n_fft = 2048 # window size\n",
        "hop_length = 512 # window hop length for STFT\n",
        "\n",
        "stft = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length)\n",
        "stft_db = librosa.amplitude_to_db(stft, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "lplt.specshow(stft, sr=sr, x_axis='time', y_axis='hz')\n",
        "plt.colorbar()\n",
        "plt.title(\"Spectrogram with amplitude\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "lplt.specshow(stft_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\n",
        "plt.colorbar()\n",
        "plt.title(\"Spectrogram with decibel log\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4UKquWvEh3xP"
      },
      "cell_type": "code",
      "source": [
        "# plot zoomed audio wave\n",
        "start = 1000\n",
        "end = 1200\n",
        "plt.figure(figsize=(16,4))\n",
        "plt.plot(audio_data[start:end])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ZU06hGsah3xP"
      },
      "cell_type": "code",
      "source": [
        "mel_spec = librosa.feature.melspectrogram(audio_data, sr=sr)\n",
        "mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "plt.figure(figsize=(16,6))\n",
        "lplt.specshow(mel_spec_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', cmap='cool')\n",
        "plt.colorbar()\n",
        "plt.title(\"Mel Spectrogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CetcQ0lhh3xP"
      },
      "cell_type": "code",
      "source": [
        "chroma = librosa.feature.chroma_stft(audio_data, sr=sr)\n",
        "plt.figure(figsize=(16,6))\n",
        "lplt.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma', cmap='coolwarm')\n",
        "plt.colorbar()\n",
        "plt.title(\"Chroma Features\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "b_BKkRBLh3xP"
      },
      "cell_type": "code",
      "source": [
        "# Computing the Correlation Matrix\n",
        "spike_cols = [col for col in df.columns if 'mean' in col]\n",
        "corr = df[spike_cols].corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(16, 11));\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(0, 25, as_cmap=True, s = 90, l = 45, n = 5)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "\n",
        "plt.title('Correlation Heatmap (for the MEAN variables)', fontsize = 20)\n",
        "plt.xticks(fontsize = 10)\n",
        "plt.yticks(fontsize = 10);\n",
        "plt.savefig(\"Corr_Heatmap.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "q0TkP9tZh3xP"
      },
      "cell_type": "code",
      "source": [
        "x = df[[\"label\", \"tempo\"]]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16, 8));\n",
        "sns.boxplot(x = \"label\", y = \"tempo\", data = x, palette = 'husl');\n",
        "\n",
        "plt.title('BPM Boxplot for Genres', fontsize = 20)\n",
        "plt.xticks(fontsize = 14)\n",
        "plt.yticks(fontsize = 10);\n",
        "plt.xlabel(\"Genre\", fontsize = 15)\n",
        "plt.ylabel(\"BPM\", fontsize = 15)\n",
        "plt.savefig(\"BPM_Boxplot.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5Ymp0rz4h3xP"
      },
      "cell_type": "code",
      "source": [
        "data = df.iloc[0:, 1:]\n",
        "y = data['label']\n",
        "X = data.loc[:, data.columns != 'label']\n",
        "\n",
        "# normalize\n",
        "cols = X.columns\n",
        "min_max_scaler = skp.MinMaxScaler()\n",
        "np_scaled = min_max_scaler.fit_transform(X)\n",
        "X = pd.DataFrame(np_scaled, columns = cols)\n",
        "\n",
        "# Top 2 pca components\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(X)\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2'])\n",
        "\n",
        "# concatenate with target label\n",
        "finalDf = pd.concat([principalDf, y], axis = 1)\n",
        "\n",
        "plt.figure(figsize = (16, 9))\n",
        "sns.scatterplot(x = \"pc1\", y = \"pc2\", data = finalDf, hue = \"label\", alpha = 0.7, s = 100);\n",
        "\n",
        "plt.title('PCA on Genres', fontsize = 20)\n",
        "plt.xticks(fontsize = 14)\n",
        "plt.yticks(fontsize = 10);\n",
        "plt.xlabel(\"Principal Component 1\", fontsize = 15)\n",
        "plt.ylabel(\"Principal Component 2\", fontsize = 15)\n",
        "plt.savefig(\"PCA_Scattert.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11hSAHpCh3xQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "\n",
        "- Treat missing values.\n",
        "- Outlier Treatment\n",
        "- Define dummy variables for categorical variables."
      ]
    },
    {
      "metadata": {
        "id": "lWaGZ8Uwh3xQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Missing Value Treatment"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "xMGjz46dh3xQ"
      },
      "cell_type": "code",
      "source": [
        "# find all columns with any NA values\n",
        "print(\"Columns with NA values are\",list(df.columns[df.isnull().any()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9-bFxHjh3xQ"
      },
      "cell_type": "markdown",
      "source": [
        "`No null values in the dataset`\n",
        "\n",
        "\n",
        "\n",
        "`There are no categorical variable as such. Hence, Dummy variable creation is not needed.`"
      ]
    },
    {
      "metadata": {
        "id": "tOSqCQzTh3xQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Encode Genre Label"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_mpEQSSEh3xQ"
      },
      "cell_type": "code",
      "source": [
        "# map labels to index\n",
        "label_index = dict()\n",
        "index_label = dict()\n",
        "for i, x in enumerate(df.label.unique()):\n",
        "    label_index[x] = i\n",
        "    index_label[i] = x\n",
        "print(label_index)\n",
        "print(index_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GrzDm-nah3xQ"
      },
      "cell_type": "code",
      "source": [
        "# update labels in df to index\n",
        "df.label = [label_index[l] for l in df.label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BgL2i3-bh3xR"
      },
      "cell_type": "markdown",
      "source": [
        "# Split Train, Dev & Test Sets"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ipdz8B55h3xR"
      },
      "cell_type": "code",
      "source": [
        "# shuffle samples\n",
        "df_shuffle = df.sample(frac=1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "JlsokMMAh3xR"
      },
      "cell_type": "code",
      "source": [
        "# remove irrelevant columns\n",
        "df_shuffle.drop(['filename', 'length'], axis=1, inplace=True)\n",
        "df_y = df_shuffle.pop('label')\n",
        "df_X = df_shuffle\n",
        "\n",
        "# split into train dev and test\n",
        "X_train, df_test_valid_X, y_train, df_test_valid_y = skms.train_test_split(df_X, df_y, train_size=0.7, random_state=seed, stratify=df_y)\n",
        "X_dev, X_test, y_dev, y_test = skms.train_test_split(df_test_valid_X, df_test_valid_y, train_size=0.66, random_state=seed, stratify=df_test_valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "G1f8avhrh3xR"
      },
      "cell_type": "code",
      "source": [
        "print(f\"Train set has {X_train.shape[0]} records out of {len(df_shuffle)} which is {round(X_train.shape[0]/len(df_shuffle)*100)}%\")\n",
        "print(f\"Dev set has {X_dev.shape[0]} records out of {len(df_shuffle)} which is {round(X_dev.shape[0]/len(df_shuffle)*100)}%\")\n",
        "print(f\"Test set has {X_test.shape[0]} records out of {len(df_shuffle)} which is {round(X_test.shape[0]/len(df_shuffle)*100)}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "crl1K7NQh3xR"
      },
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts()[0]/y_train.shape[0]*100)\n",
        "print(y_dev.value_counts()[0]/y_dev.shape[0]*100)\n",
        "print(y_test.value_counts()[0]/y_test.shape[0]*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jdsyf94h3xR"
      },
      "cell_type": "markdown",
      "source": [
        "## Scale the Features"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lcbYALTEh3xR"
      },
      "cell_type": "code",
      "source": [
        "scaler = skp.StandardScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_dev = pd.DataFrame(scaler.transform(X_dev), columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQ-iRtBnh3xS"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "d0oUgjgyh3xS"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TF version:-\", tf.__version__)\n",
        "import keras as k\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "ANt0t0hwh3xS"
      },
      "cell_type": "code",
      "source": [
        "ACCURACY_THRESHOLD = 0.94\n",
        "\n",
        "class myCallback(k.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n",
        "            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def trainModel(model, epochs, optimizer):\n",
        "    batch_size = 128\n",
        "    callback = myCallback()\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics='accuracy'\n",
        "    )\n",
        "    return model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=epochs,\n",
        "                     batch_size=batch_size, callbacks=[callback])\n",
        "\n",
        "def plotHistory(history):\n",
        "    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n",
        "    pd.DataFrame(history.history).plot(figsize=(12,6))\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "KUTpfzeKh3xS"
      },
      "cell_type": "code",
      "source": [
        "model_1 = k.models.Sequential([\n",
        "    k.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    k.layers.Dense(128, activation='relu'),\n",
        "    k.layers.Dense(64, activation='relu'),\n",
        "    k.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "print(model_1.summary())\n",
        "model_1_history = trainModel(model=model_1, epochs=70, optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-P0WGwoph3xS"
      },
      "cell_type": "code",
      "source": [
        "plotHistory(model_1_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "c_Fk3scvh3xS"
      },
      "cell_type": "code",
      "source": [
        "model_2 = k.models.Sequential([\n",
        "    k.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(256, activation='relu'),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(128, activation='relu'),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(64, activation='relu'),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "print(model_2.summary())\n",
        "model_2_history = trainModel(model=model_2, epochs=100, optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "N2TvQ2_yh3xX"
      },
      "cell_type": "code",
      "source": [
        "plotHistory(model_2_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "iwzYkNgih3xX"
      },
      "cell_type": "code",
      "source": [
        "model_3 = k.models.Sequential([\n",
        "    k.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(256, activation='relu'),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(128, activation='relu'),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(64, activation='relu'),\n",
        "    k.layers.Dropout(0.2),\n",
        "\n",
        "    k.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "print(model_3.summary())\n",
        "model_3_history = trainModel(model=model_3, epochs=700, optimizer='sgd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "KNHBNi_sh3xX"
      },
      "cell_type": "code",
      "source": [
        "plotHistory(model_3_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "BTOaFXQeh3xX"
      },
      "cell_type": "code",
      "source": [
        "model_4 = k.models.Sequential([\n",
        "    k.layers.Dense(1024, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    k.layers.Dropout(0.3),\n",
        "\n",
        "    k.layers.Dense(512, activation='relu'),\n",
        "    k.layers.Dropout(0.3),\n",
        "\n",
        "    k.layers.Dense(256, activation='relu'),\n",
        "    k.layers.Dropout(0.3),\n",
        "\n",
        "    k.layers.Dense(128, activation='relu'),\n",
        "    k.layers.Dropout(0.3),\n",
        "\n",
        "    k.layers.Dense(64, activation='relu'),\n",
        "    k.layers.Dropout(0.3),\n",
        "\n",
        "    k.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "print(model_4.summary())\n",
        "model_4_history = trainModel(model=model_4, epochs=500, optimizer='rmsprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xTD3zXuUh3xY"
      },
      "cell_type": "code",
      "source": [
        "plotHistory(model_4_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ig3Xwkrph3xY"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rOhfueQjh3xY"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc  = model_4.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"The test Loss is :\",test_loss)\n",
        "print(\"\\nThe Best test Accuracy is :\",test_acc*100)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}